{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 - Part 1: Web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary features\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Scrape data from indeed.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize lists to store relevant features\n",
    "titles = []\n",
    "companies = []\n",
    "summaries = []\n",
    "locations = []\n",
    "salaries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape data from the first page of results\n",
    "#First get html for search page\n",
    "url = 'https://au.indeed.com/jobs?q=data+scientist&l=Australia'\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "#Then make a list of all the urls of the individual job listings\n",
    "link = soup.findAll('a',{'data-tn-element':'jobTitle'})\n",
    "urls = []\n",
    "for i in range(len(link)):\n",
    "    urls.append(link[i]['href'])\n",
    "     \n",
    "#Now iterate through this list to scrape relevant information from each page\n",
    "for address in urls:\n",
    "    sub_url = \"https://au.indeed.com/\"+str(address)\n",
    "    response2 = requests.get(sub_url)\n",
    "    html2 = response2.text\n",
    "    soup2 = BeautifulSoup(html2, 'lxml')\n",
    "    title = soup2.findAll('b',{'class':'jobtitle'})\n",
    "    [titles.append(title[i].text) for i in range(len(title))]\n",
    "    for x in soup2.findAll('div',{'data-tn-component':'jobHeader'}):\n",
    "        company = x.find('span',{'class':'company'})\n",
    "        [companies.append(company.text)]\n",
    "        loc = x.find('span',{'class':'location'})\n",
    "        [locations.append(loc.text)]    \n",
    "        try:\n",
    "            salary = x.find('span',{'class':'no-wrap'})\n",
    "            [salaries.append(salary.text)]\n",
    "        except:\n",
    "            salary = 'No info'\n",
    "            [salaries.append(salary)]\n",
    "    summ = (soup2.findAll('span',{'class':'summary'}))\n",
    "    [summaries.append(summ[i].text) for i in range(len(summ))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through the remaining pages:\n",
    "for i in range(10,540,10):\n",
    "    url = 'https://au.indeed.com/jobs?q=data+scientist&l=Australia&start='+str(i)\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    link = soup.findAll('a',{'data-tn-element':'jobTitle'})\n",
    "    urls = []\n",
    "    for i in range(len(link)):\n",
    "        urls.append(link[i]['href'])\n",
    "    for address in urls:\n",
    "        sub_url = \"https://au.indeed.com/\"+str(address)\n",
    "        response2 = requests.get(sub_url)\n",
    "        html2 = response2.text\n",
    "        soup2 = BeautifulSoup(html2, 'lxml')\n",
    "        title = soup2.findAll('b',{'class':'jobtitle'})\n",
    "        [titles.append(title[i].text) for i in range(len(title))]\n",
    "        for x in soup2.findAll('div',{'data-tn-component':'jobHeader'}):\n",
    "            company = x.find('span',{'class':'company'})\n",
    "            [companies.append(company.text)]\n",
    "            loc = x.find('span',{'class':'location'})\n",
    "            [locations.append(loc.text)]    \n",
    "            try:\n",
    "                salary = x.find('span',{'class':'no-wrap'})\n",
    "                [salaries.append(salary.text)]\n",
    "            except:\n",
    "                salary = 'No info'\n",
    "                [salaries.append(salary)]\n",
    "        summ = (soup2.findAll('span',{'class':'summary'}))\n",
    "        [summaries.append(summ[i].text) for i in range(len(summ))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat for 'data analyst' jobs\n",
    "url = 'https://au.indeed.com/jobs?q=data+analyst&l=Australia'\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "link = soup.findAll('a',{'data-tn-element':'jobTitle'})\n",
    "urls = []\n",
    "for i in range(len(link)):\n",
    "    urls.append(link[i]['href'])\n",
    "for address in urls:\n",
    "    sub_url = \"https://au.indeed.com/\"+str(address)\n",
    "    response2 = requests.get(sub_url)\n",
    "    html2 = response2.text\n",
    "    soup2 = BeautifulSoup(html2, 'lxml')\n",
    "    title = soup2.findAll('b',{'class':'jobtitle'})\n",
    "    [titles.append(title[i].text) for i in range(len(title))]\n",
    "    for x in soup2.findAll('div',{'data-tn-component':'jobHeader'}):\n",
    "        company = x.find('span',{'class':'company'})\n",
    "        [companies.append(company.text)]\n",
    "        loc = x.find('span',{'class':'location'})\n",
    "        [locations.append(loc.text)]    \n",
    "        try:\n",
    "            salary = x.find('span',{'class':'no-wrap'})\n",
    "            [salaries.append(salary.text)]\n",
    "        except:\n",
    "            salary = 'No info'\n",
    "            [salaries.append(salary)]\n",
    "    summ = (soup2.findAll('span',{'class':'summary'}))\n",
    "    [summaries.append(summ[i].text) for i in range(len(summ))]\n",
    "for i in range(10,540,10):\n",
    "    url = 'https://au.indeed.com/jobs?q=data+analyst&l=Australia&start='+str(i)\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    link = soup.findAll('a',{'data-tn-element':'jobTitle'})\n",
    "    urls = []\n",
    "    for i in range(len(link)):\n",
    "        urls.append(link[i]['href'])\n",
    "    for address in urls:\n",
    "        sub_url = \"https://au.indeed.com/\"+str(address)\n",
    "        response2 = requests.get(sub_url)\n",
    "        html2 = response2.text\n",
    "        soup2 = BeautifulSoup(html2, 'lxml')\n",
    "        title = soup2.findAll('b',{'class':'jobtitle'})\n",
    "        [titles.append(title[i].text) for i in range(len(title))]\n",
    "        for x in soup2.findAll('div',{'data-tn-component':'jobHeader'}):\n",
    "            company = x.find('span',{'class':'company'})\n",
    "            [companies.append(company.text)]\n",
    "            loc = x.find('span',{'class':'location'})\n",
    "            [locations.append(loc.text)]    \n",
    "            try:\n",
    "                salary = x.find('span',{'class':'no-wrap'})\n",
    "                [salaries.append(salary.text)]\n",
    "            except:\n",
    "                salary = 'No info'\n",
    "                [salaries.append(salary)]\n",
    "        summ = (soup2.findAll('span',{'class':'summary'}))\n",
    "        [summaries.append(summ[i].text) for i in range(len(summ))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Create a dataframe and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe\n",
    "df = pd.DataFrame({'title':titles,'company':companies,'location':locations,'salary':salaries,'summary':summaries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(798, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allianz</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>Full-time, Temporary</td>\n",
       "      <td>Reporting directly to the Manager Business Ana...</td>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Teradata</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>No info</td>\n",
       "      <td>The Data Scientist produces intelligence from ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>carsales.com.au</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>Full-time, Permanent</td>\n",
       "      <td>We are currently on the hunt for a Data Scient...</td>\n",
       "      <td>Data Scientist - 12 month contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EY</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>No info</td>\n",
       "      <td>About us\\nEY DnA is the data and advanced anal...</td>\n",
       "      <td>Data Scientist - Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Culture Amp</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>No info</td>\n",
       "      <td>Culture Amp is the world's most powerfully sim...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           company       location                salary  \\\n",
       "0          Allianz  Melbourne VIC  Full-time, Temporary   \n",
       "1         Teradata  Melbourne VIC               No info   \n",
       "2  carsales.com.au  Melbourne VIC  Full-time, Permanent   \n",
       "3               EY  Melbourne VIC               No info   \n",
       "4      Culture Amp  Melbourne VIC               No info   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Reporting directly to the Manager Business Ana...   \n",
       "1  The Data Scientist produces intelligence from ...   \n",
       "2  We are currently on the hunt for a Data Scient...   \n",
       "3  About us\\nEY DnA is the data and advanced anal...   \n",
       "4  Culture Amp is the world's most powerfully sim...   \n",
       "\n",
       "                                title  \n",
       "0                      DATA SCIENTIST  \n",
       "1                      Data Scientist  \n",
       "2  Data Scientist - 12 month contract  \n",
       "3          Data Scientist - Melbourne  \n",
       "4                      Data Scientist  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export dataframe to csv\n",
    "filepath = 'jobs.csv'\n",
    "df.to_csv(filepath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
